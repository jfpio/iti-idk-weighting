# This file was autogenerated by uv via the following command:
#    uv pip compile pyproject.toml -o requirements.txt
absl-py==2.3.1
    # via
    #   honest-llama (pyproject.toml)
    #   rouge-score
accelerate==1.10.1
    # via honest-llama (pyproject.toml)
aiohappyeyeballs==2.6.1
    # via
    #   honest-llama (pyproject.toml)
    #   aiohttp
aiohttp==3.12.15
    # via
    #   honest-llama (pyproject.toml)
    #   fsspec
aiosignal==1.4.0
    # via
    #   honest-llama (pyproject.toml)
    #   aiohttp
attrs==25.3.0
    # via
    #   honest-llama (pyproject.toml)
    #   aiohttp
certifi==2025.8.3
    # via
    #   honest-llama (pyproject.toml)
    #   requests
charset-normalizer==3.4.3
    # via
    #   honest-llama (pyproject.toml)
    #   requests
click==8.3.0
    # via
    #   honest-llama (pyproject.toml)
    #   nltk
contourpy==1.3.3
    # via
    #   honest-llama (pyproject.toml)
    #   matplotlib
cycler==0.12.1
    # via
    #   honest-llama (pyproject.toml)
    #   matplotlib
datasets==4.1.1
    # via
    #   honest-llama (pyproject.toml)
    #   evaluate
dill==0.4.0
    # via
    #   honest-llama (pyproject.toml)
    #   datasets
    #   evaluate
    #   multiprocess
einops==0.8.1
    # via honest-llama (pyproject.toml)
evaluate==0.4.6
    # via honest-llama (pyproject.toml)
filelock==3.19.1
    # via
    #   honest-llama (pyproject.toml)
    #   datasets
    #   huggingface-hub
    #   torch
    #   transformers
fire==0.7.1
    # via honest-llama (pyproject.toml)
fonttools==4.60.0
    # via
    #   honest-llama (pyproject.toml)
    #   matplotlib
frozenlist==1.7.0
    # via
    #   honest-llama (pyproject.toml)
    #   aiohttp
    #   aiosignal
fsspec==2025.9.0
    # via
    #   honest-llama (pyproject.toml)
    #   datasets
    #   evaluate
    #   huggingface-hub
    #   torch
hf-xet==1.1.10
    # via
    #   honest-llama (pyproject.toml)
    #   huggingface-hub
huggingface-hub==0.35.0
    # via
    #   honest-llama (pyproject.toml)
    #   accelerate
    #   datasets
    #   evaluate
    #   tokenizers
    #   transformers
idna==3.10
    # via
    #   honest-llama (pyproject.toml)
    #   requests
    #   yarl
jinja2==3.1.6
    # via
    #   honest-llama (pyproject.toml)
    #   torch
joblib==1.5.2
    # via
    #   honest-llama (pyproject.toml)
    #   nltk
    #   pynndescent
    #   scikit-learn
kiwisolver==1.4.9
    # via
    #   honest-llama (pyproject.toml)
    #   matplotlib
llvmlite==0.45.0
    # via
    #   honest-llama (pyproject.toml)
    #   numba
    #   pynndescent
markupsafe==3.0.2
    # via
    #   honest-llama (pyproject.toml)
    #   jinja2
matplotlib==3.10.6
    # via
    #   honest-llama (pyproject.toml)
    #   seaborn
mpmath==1.3.0
    # via
    #   honest-llama (pyproject.toml)
    #   sympy
multidict==6.6.4
    # via
    #   honest-llama (pyproject.toml)
    #   aiohttp
    #   yarl
multiprocess==0.70.16
    # via
    #   honest-llama (pyproject.toml)
    #   datasets
    #   evaluate
networkx==3.5
    # via
    #   honest-llama (pyproject.toml)
    #   torch
nltk==3.9.1
    # via
    #   honest-llama (pyproject.toml)
    #   rouge-score
numba==0.62.0
    # via
    #   honest-llama (pyproject.toml)
    #   pynndescent
    #   umap-learn
numpy==2.3.3
    # via
    #   honest-llama (pyproject.toml)
    #   accelerate
    #   contourpy
    #   datasets
    #   evaluate
    #   matplotlib
    #   numba
    #   pandas
    #   rouge-score
    #   scikit-learn
    #   scipy
    #   seaborn
    #   torchvision
    #   transformers
    #   umap-learn
packaging==25.0
    # via
    #   honest-llama (pyproject.toml)
    #   accelerate
    #   datasets
    #   evaluate
    #   huggingface-hub
    #   matplotlib
    #   transformers
pandas==2.3.2
    # via
    #   honest-llama (pyproject.toml)
    #   datasets
    #   evaluate
    #   seaborn
pillow==11.3.0
    # via
    #   honest-llama (pyproject.toml)
    #   matplotlib
    #   torchvision
propcache==0.3.2
    # via
    #   honest-llama (pyproject.toml)
    #   aiohttp
    #   yarl
psutil==7.1.0
    # via
    #   honest-llama (pyproject.toml)
    #   accelerate
pyarrow==21.0.0
    # via
    #   honest-llama (pyproject.toml)
    #   datasets
pynndescent==0.5.13
    # via
    #   honest-llama (pyproject.toml)
    #   umap-learn
pyparsing==3.2.4
    # via
    #   honest-llama (pyproject.toml)
    #   matplotlib
python-dateutil==2.9.0.post0
    # via
    #   honest-llama (pyproject.toml)
    #   matplotlib
    #   pandas
pytz==2025.2
    # via
    #   honest-llama (pyproject.toml)
    #   pandas
pyyaml==6.0.2
    # via
    #   honest-llama (pyproject.toml)
    #   accelerate
    #   datasets
    #   huggingface-hub
    #   transformers
regex==2025.9.18
    # via
    #   honest-llama (pyproject.toml)
    #   nltk
    #   transformers
requests==2.32.5
    # via
    #   honest-llama (pyproject.toml)
    #   datasets
    #   evaluate
    #   huggingface-hub
    #   transformers
rouge-score==0.1.2
    # via honest-llama (pyproject.toml)
safetensors==0.6.2
    # via
    #   honest-llama (pyproject.toml)
    #   accelerate
    #   transformers
scikit-learn==1.7.2
    # via
    #   honest-llama (pyproject.toml)
    #   pynndescent
    #   umap-learn
scipy==1.16.2
    # via
    #   honest-llama (pyproject.toml)
    #   pynndescent
    #   scikit-learn
    #   umap-learn
seaborn==0.13.2
    # via honest-llama (pyproject.toml)
sentencepiece==0.2.1
    # via honest-llama (pyproject.toml)
setuptools==80.9.0
    # via
    #   honest-llama (pyproject.toml)
    #   torch
six==1.17.0
    # via
    #   honest-llama (pyproject.toml)
    #   python-dateutil
    #   rouge-score
sympy==1.14.0
    # via
    #   honest-llama (pyproject.toml)
    #   torch
tabulate==0.9.0
    # via honest-llama (pyproject.toml)
termcolor==3.1.0
    # via
    #   honest-llama (pyproject.toml)
    #   fire
threadpoolctl==3.6.0
    # via
    #   honest-llama (pyproject.toml)
    #   scikit-learn
tokenizers==0.22.0
    # via
    #   honest-llama (pyproject.toml)
    #   transformers
torch==2.8.0
    # via
    #   honest-llama (pyproject.toml)
    #   accelerate
    #   torchaudio
    #   torchvision
torchaudio==2.8.0
    # via honest-llama (pyproject.toml)
torchvision==0.23.0
    # via honest-llama (pyproject.toml)
tqdm==4.67.1
    # via
    #   honest-llama (pyproject.toml)
    #   datasets
    #   evaluate
    #   huggingface-hub
    #   nltk
    #   transformers
    #   umap-learn
transformers==4.56.1
    # via honest-llama (pyproject.toml)
typing-extensions==4.15.0
    # via
    #   honest-llama (pyproject.toml)
    #   huggingface-hub
    #   torch
tzdata==2025.2
    # via
    #   honest-llama (pyproject.toml)
    #   pandas
umap-learn==0.5.9.post2
    # via honest-llama (pyproject.toml)
urllib3==2.5.0
    # via
    #   honest-llama (pyproject.toml)
    #   requests
xxhash==3.5.0
    # via
    #   honest-llama (pyproject.toml)
    #   datasets
    #   evaluate
yarl==1.20.1
    # via
    #   honest-llama (pyproject.toml)
    #   aiohttp
